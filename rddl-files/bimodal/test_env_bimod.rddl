//Simple MDP environment with 4 states and 2 actions
//See state diagram for more details
//rewards sampled from bimodal and unimodal distributions


domain test_env_bimod {

        requirements { 
                integer-valued,         //this domain uses integer variables
                intermediate-nodes,     //this domain uses intermediate fluents
                multivalued             //this domain uses enumerated variables
        };
        
        //user defined types
        types { 
	              enum_state : {@state0, @state1, @state2, @state3};  
		      w : {@left, @right};
        };
        
        pvariables {
                state : {state-fluent, int, default = 0};             //current state
	              action : {action-fluent, bool, default = false};      //current action
	              done : {state-fluent, bool, default = false};         //done state variable
	              sample : {interm-fluent, enum_state, level = 1};      //intermediate fluent used to update state variable
		      weight : {interm-fluent, w, level = 1};             //intermediate fluent used to sample from the bimodal distributions
        };

        cpfs {  
                //choose a state with given probabilities that sum to 1
	        sample = Discrete(enum_state, 
                                @state0 : 0,
                                @state1 : if (action == false ^ state == 0) then 0.75 else 0, 
                                @state2 : if (action == false ^ state == 0) then 0.25 else if (action == true ^ state == 0) then 1 else 0,
                                @state3 : if (state == 2 | state == 1 |state == 3) then 1 else 0
                                );

		weight = Discrete(w,
				@left : 0.5, 			//50 percent chance of sampling from the left distribution
				@right : 0.5
				);


                done' = if (sample == @state3) then true else false;  //updating new done state 
                
                //updating new state variable according to sampled state given state action pair
                state' = switch(sample) {  
                        case @state0 : 0,
                        case @state1 : 1,
                        case @state2 : 2,
                        case @state3 : 3
                        };

             };
       
       
       //sampling rewards from normal distributions given state action pairs
       reward = 
              if (action == false ^ state == 0 ) then Normal(1,0.1) 
	      else if (state == 0 ^ action == true) then -0.5 
              else if (state == 1 ^ action == false) then (if (weight == @left) then Normal(-1,0.001) else Normal(0, 0.001))
              else if (state == 1 ^ action == true) then Normal(0.5,0.5) 
	      else if (state == 2 ^ action == false) then (if (weight == @left) then Normal(-1,0.2) else Normal(2,0.2)) 
              else if (state == 2 ^ action == true) then Normal(0,1) 
	      else 0;
}
